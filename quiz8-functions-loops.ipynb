{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"quiz8-functions-loops.ipynb\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⌛️ Quiz 6 - Using Functions\n",
    "\n",
    "This quiz will evaluate your mastery of using functions in Python. Functions provide a way to isolate code that you want to use repeatedly, and they allow you to pass in data to the code and get data back out of the code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "You will click on the following link to start your quiz. Do not start the quiz before your lab section. We have checks in place to ensure that you do not start the quiz early. If you do, you will receive a 0 on the quiz. Furthermore, it could be considered an academic integrity violation.\n",
    "\n",
    "[CLICK HERE TO START YOUR QUIZ IN LAB](https://online.wiseattend.com/student/testLink?c=ENGR131&k=0464) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entering Your Information for Credit\n",
    "\n",
    "To receive credit for assignments it is important we can identify your work from others. To do this we will ask you to enter your information in the following code block.\n",
    "\n",
    "### Before you begin\n",
    "\n",
    "Run the block of code at the top of the notebook that imports and sets up the autograder. This will allow you to check your work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "\n",
    "from ENGR131_Util_2024 import cell_logger, StudentInfoForm, responses, upsert_to_json_file\n",
    "# Register the log function to be called before any cell is executed\n",
    "get_ipython().events.register('pre_run_cell', cell_logger)\n",
    "responses[\"assignment\"] = \"quiz8\"\n",
    "\n",
    "StudentInfoForm(**responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1: Stress on a Beam**\n",
    "\n",
    "You are a structural engineer responsible for selecting a beam to support a load. You know the beam is subjected to a uniform load. It is your job to create a function that will calculate the minimum beam design specifications to ensure that the beam will not yield under the expected load.\n",
    "\n",
    "The stress, $\\sigma$, on a beam subjected to a uniform load is given by the equation:\n",
    "\n",
    "$$ \n",
    "\\sigma = \\frac{M y}{I} \\tag{1}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $M$ is the moment of the force applied to the beam (in Newton-meters, Nm),\n",
    "- $y$ is the distance from the neutral axis to the point at which the stress is being calculated (in meters, m),\n",
    "- $I$ is the moment of inertia of the beam's cross-sectional area (in meters to the fourth power, m\\(^4\\)).\n",
    "\n",
    "When selecting a beam it is important to be able to include a safety factor in the design. The safety factor is a multiplier that is applied to the calculated stress to ensure that the beam will not fail under the expected load.\n",
    "\n",
    "If the stress on the beam is sigma, the required design specifications including the safety factor are given by:\n",
    "\n",
    "$$ \\sigma_{\\text{yield}} = \\text{Safety Factor} \\times \\sigma  \\tag{2}$$\n",
    "\n",
    "Write Python code to do the following:\n",
    "\n",
    "* Define a function called `beam_stress` which accepts three input arguments: `M`, `y`, and `I`, and a fourth optional argument called `safety_factor` which defaults to 1.0.\n",
    "* Define a variable called `sigma` and set it equal to the result of equation (1) above.\n",
    "* Define a variable called `sigma_yield` and set it equal to the result of the equation (2) above.\n",
    "* Have your function print the response: `The stress on the beam is: <sigma> N/m^2, and the required beam yield strength is <sigma_yield> N/m^2`, where `<sigma>`, and `<sigma_yield>` are the integer values of the variable for the stress on the beam and yield strength respectively.\n",
    "* Implement your function so that it returns the required yield stress of the beam for a given input.\n",
    "\n",
    "Provide an example usage of your function by calling it with the following inputs:\n",
    "* `M = 1000` Nm\n",
    "* `y = 0.1` m\n",
    "* `I = 0.0001` m\\(^4\\)\n",
    "* `safety_factor = 1.5`\n",
    "\n",
    "Save the output of the function call to a variable `required_yield_strength`.\n",
    "\n",
    "Your code should print the response: \n",
    "\n",
    "Note: You can control the precision of the output by using string formatting to round the output to a specific number of decimal places. For example, to round the output to 2 decimal places, you can use the following code:\n",
    "\n",
    "```python\n",
    "print(f\"{sigma:0.2f}\")\n",
    "```\n",
    "\n",
    "Your code replaces the prompt:  `...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your function for beam_stress goes here\n",
    "...\n",
    "\n",
    "# Example usage:\n",
    "M = ...\n",
    "y = ...\n",
    "I = ...\n",
    "safety_factor = ...\n",
    "\n",
    "# Call the function with example inputs save to a variable `required_yield_strength`\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1-stress-on-beam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2: Detecting the First Signal Peak Above a Threshold 8**\n",
    "\n",
    "Write a Python function `threshold_peak` that takes a sequence of signal strength measurements (represented as a list of integers) as a variable `signal`. The goal is to identify the first measurement that exceeds a predefined `threshold` value, which indicates the occurrence of a significant signal peak. Once a peak exceeding the threshold is found, the program should return the *index* (position) of this measurement in the dataset and the *value* of the peak, as a tuple then terminate the search.\n",
    "\n",
    "\n",
    "Requirements:\n",
    "1. Write a function `threshold_peak` that takes two input arguments: `signal` (a list of integers) and `threshold` (an integer).\n",
    "   \n",
    "   1. Use a for loop to iterate through the signal_measurements list.\n",
    "Within the loop, implement a condition to check if the current measurement exceeds the threshold.\n",
    "   1. Print the index of the first measurement that exceeds the threshold and the value of this measurement. The print statement should read `First signal peak above threshold found at index <index> with value <value>.`, where <index> and <value> are the index and value of the first measurement that exceeds the threshold.\n",
    "   2. If a measurement exceeding the threshold is found, use a return statement to exit the loop immediately and return a tuple containing the index of the measurement and the value of the measurement.\n",
    "   3. If no measurement exceeds the threshold, print a message: `No significant signal peak was detected above the threshold of <threshold>.`, where <threshold> is the value of the threshold.\n",
    "1. Test your function by calling it with the provided inputs. Save the output of the function call to a variable `peak`.\n",
    "\n",
    "Hints:\n",
    "* Use the enumerate() function to get both the index and the value of each item when iterating through the list with a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample signal measurements\n",
    "signal_measurements = [10, 12, 7, 5, 10, 18, 21, 4, 3, 2, 17, 20]\n",
    "\n",
    "# Threshold value\n",
    "threshold = 20\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2-detecting-threshold-signal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting Your Assignment\n",
    "\n",
    "To submit your assignment please use the following link the assignment on GitHub classroom.\n",
    "   \n",
    "Use this [link](https://classroom.github.com/a/adE3mdGL) add link to navigate to the assignment on GitHub classroom.\n",
    "\n",
    "If you need further instructions on submitting your assignment please look at Lab 1. \n",
    "\n",
    "## Viewing your score\n",
    "\n",
    "Each `.ipynb` file you have uploaded will have a file with the name of your file + `Grade_Report.md`. You can view this file by clicking on the file name. This will show you the results of the autograder. \n",
    "\n",
    "We have both public and hidden tests. You will be able to see the score of both tests, but not the specific details of why the test passed or failed. \n",
    "\n",
    "```{note}\n",
    "In python and particularly jupyter notebooks it is common that during testing you run cells in a different order, or run cells and modify them. This can cause there to be local variables needed for your solution that would not be recreated on running your code again from scratch. Your assignment will be graded based on running your code from scratch. This means before you submit your assignment you should restart the kernel and run all cells. You can do this by clicking `Kernel` and selecting `Restart and Run All`. If you code does not run as expected after restarting the kernel and running all cells it means you have an error in your code. \n",
    "```\n",
    "\n",
    "## Fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1-stress-on-beam": {
     "name": "q1-stress-on-beam",
     "points": 12,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score\n>>> assert M == 1000, 'The value of M is not correct.'\n>>> assert y == 0.1, 'The value of y is not correct.'\n>>> assert I == 0.0001, 'The value of I is not correct.'\n>>> assert safety_factor == 1.5, 'The value of the safety factor is not correct.'\n>>> drexel_jupyter_logger.variable_logger_csv('0, 1', 'q1_1')\n>>> drexel_jupyter_logger.variable_logger_csv('0, 1', 'q1_2')\n>>> drexel_jupyter_logger.variable_logger_csv('0, 1', 'q1_3')\n>>> drexel_jupyter_logger.variable_logger_csv('0, 2', 'q1_4')\n>>> drexel_jupyter_logger.variable_logger_csv('0, 2', 'q1_5')\n>>> drexel_jupyter_logger.variable_logger_csv('0, 2', 'q1_6')\n>>> drexel_jupyter_logger.variable_logger_csv('0, 3', 'q1_7')\n>>> drexel_jupyter_logger.variable_logger_csv('0, 2', 'q2_1')\n>>> drexel_jupyter_logger.variable_logger_csv('0, 2', 'q2_2')\n>>> drexel_jupyter_logger.variable_logger_csv('0, 3', 'q2_3')\n>>> drexel_jupyter_logger.variable_logger_csv('0, 3', 'q2_4')\n>>> drexel_jupyter_logger.variable_logger_csv('0, 4', 'q2_5')\n>>> scorer = submit_score()\n>>> question_id = 'q1_1'\n>>> if M == 1000 and y == 0.1 and (I == 0.0001) and (safety_factor == 1.5):\n...     drexel_jupyter_logger.variable_logger_csv('1, 1', question_id)\n...     score = 1\n... else:\n...     score = 0\n>>> response = {'question_id': question_id, 'score': 1, 'max_score': 1, 'student_response': f'{M}, {y}, {I}, {safety_factor}'}\n>>> scorer.add_response(response)\n>>> scorer.submit()\nLogin successful\nData successfully uploaded to the server\nresponses successfully uploaded to database\n",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "Test values are implemented correctly."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score\n>>> scorer = submit_score()\n>>> question_id = 'q1_2'\n>>> assert required_yield_strength == 1500000, 'The required yield stress is not calculated correctly.'\n>>> if required_yield_strength == 1500000:\n...     drexel_jupyter_logger.variable_logger_csv('1, 1', question_id)\n...     score = 1\n... else:\n...     score = 0\n>>> response = {'question_id': question_id, 'score': score, 'max_score': 1, 'student_response': f'{required_yield_strength}'}\n>>> scorer.add_response(response)\n>>> scorer.submit()\nLogin successful\nData successfully uploaded to the server\nresponses successfully uploaded to database\n",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "Test for stress implemented correctly."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> from ENGR131_Util_2024 import submit_score\n>>> scorer = submit_score()\n>>> question_id = 'q1_3'\n>>> with patch('builtins.print') as mock_print:\n...     assert type(beam_stress(1, 2, 3, 1)) == float, 'The function does not return a numerical value of type float.'\n...     if type(beam_stress(1, 2, 3, 1)) == float:\n...         drexel_jupyter_logger.variable_logger_csv('1, 1', question_id)\n...         score = 1\n...     else:\n...         score = 0\n...     response = {'question_id': question_id, 'score': score, 'max_score': 1, 'student_response': f'{type(beam_stress(1, 2, 3, 1))}'}\n>>> scorer.add_response(response)\n>>> scorer.submit()\nLogin successful\nData successfully uploaded to the server\nresponses successfully uploaded to database\n",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "Function correctly returns a numerical value."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> from ENGR131_Util_2024 import submit_score\n>>> scorer = submit_score()\n>>> question_id = 'q1_4'\n>>> (M, y, I, safety_factor) = (2000, 0.4, 0.002, 4)\n>>> with patch('builtins.print') as mock_print:\n...     assert beam_stress(M, y, I) == 400000.0, 'yield stress with default safety factor is not correct.'\n...     if beam_stress(M, y, I) == 400000.0:\n...         score = 2\n...         drexel_jupyter_logger.variable_logger_csv('2, 2', question_id)\n...     else:\n...         score = 0\n...     response = {'question_id': question_id, 'score': score, 'max_score': 2, 'student_response': f'{beam_stress(M, y, I)}'}\n>>> scorer.add_response(response)\n>>> scorer.submit()\nLogin successful\nData successfully uploaded to the server\nresponses successfully uploaded to database\n",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "default safety factor is implemented correctly."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> from ENGR131_Util_2024 import submit_score\n>>> scorer = submit_score()\n>>> question_id = 'q1_5'\n>>> (M, y, I, safety_factor) = (2000, 0.4, 0.002, 4)\n>>> with patch('builtins.print') as mock_print:\n...     out = beam_stress(M, y, I, safety_factor)\n...     assert out == 1600000, 'Safety factor implemented correctly.'\n...     if out == 1600000:\n...         score = 2\n...         drexel_jupyter_logger.variable_logger_csv('2, 2', question_id)\n...     else:\n...         score = 0\n...     response = {'question_id': question_id, 'score': score, 'max_score': 2, 'student_response': f'{out}'}\n>>> scorer.add_response(response)\n>>> scorer.submit()\nLogin successful\nData successfully uploaded to the server\nresponses successfully uploaded to database\n",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "safety factor is implemented correctly."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> import inspect\n>>> from ENGR131_Util_2024 import submit_score\n>>> scorer = submit_score()\n>>> question_id = 'q1_6'\n>>> signature = inspect.signature(beam_stress)\n>>> parameters = signature.parameters\n>>> assert len(parameters) == 4, f'Expected 4 parameters, found {len(parameters)}'\n>>> safety_factor_param = parameters.get('safety_factor')\n>>> assert safety_factor_param is not None, 'Safety factor parameter missing.'\n>>> assert safety_factor_param.default != inspect.Parameter.empty, 'Safety factor does not have a default value, thus not optional.'\n>>> if len(parameters) == 4 and safety_factor_param is not None and (safety_factor_param.default != inspect.Parameter.empty):\n...     score = 2\n...     drexel_jupyter_logger.variable_logger_csv('2, 2', question_id)\n... else:\n...     score = 0\n>>> response = {'question_id': question_id, 'score': score, 'max_score': 2, 'student_response': f'{len(parameters)}, {safety_factor_param.default}'}\n>>> scorer.add_response(response)\n>>> scorer.submit()\nLogin successful\nData successfully uploaded to the server\nresponses successfully uploaded to database\n",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "Input parameters is is correctly defined."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> from ENGR131_Util_2024 import submit_score\n>>> scorer = submit_score()\n>>> question_id = 'q1_7'\n>>> expected_message = 'The stress on the beam is: 400000 N/m^2, and the required beam yield strength is 400000 N/m^2'\n>>> with patch('builtins.print') as mock_print:\n...     (M, y, I) = (2000, 0.4, 0.002)\n...     out = beam_stress(M, y, I)\n...     mock_print.assert_called_once_with(expected_message)\n>>> if mock_print.call_args[0][0] == expected_message:\n...     score = 3\n...     drexel_jupyter_logger.variable_logger_csv('3, 3', question_id)\n... else:\n...     score = 0\n>>> response = {'question_id': question_id, 'score': score, 'max_score': 3, 'student_response': f'{mock_print.call_args[0][0]}'}\n>>> scorer.add_response(response)\n>>> scorer.submit()\nLogin successful\nData successfully uploaded to the server\nresponses successfully uploaded to database\n",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "Input parameters is is correctly defined."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2-detecting-threshold-signal": {
     "name": "q2-detecting-threshold-signal",
     "points": 14,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import drexel_jupyter_logger\n>>> import inspect\n>>> from ENGR131_Util_2024 import submit_score\n>>> scorer = submit_score()\n>>> question_id = 'q2_1'\n>>> signature = inspect.signature(threshold_peak)\n>>> parameters = signature.parameters\n>>> assert len(parameters) == 2, f'Expected 2 parameters, found {len(parameters)}'\n>>> assert 'threshold_peak' in locals(), 'Function threshold_peak is not defined.'\n>>> assert callable(threshold_peak), 'threshold_peak is not callable.'\n>>> if len(parameters) == 2 and 'threshold_peak' in locals() and callable(threshold_peak):\n...     score = 2\n...     drexel_jupyter_logger.variable_logger_csv('2, 2', question_id)\n... else:\n...     score = 0\n>>> response = {'question_id': question_id, 'score': score, 'max_score': 2, 'student_response': f'{len(parameters)}, {callable(threshold_peak)}'}\n>>> scorer.add_response(response)\n>>> scorer.submit()\nLogin successful\nData successfully uploaded to the server\nresponses successfully uploaded to database\n",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "Function correctly implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> from ENGR131_Util_2024 import submit_score\n>>> scorer = submit_score()\n>>> question_id = 'q2_2'\n>>> expected_message = 'First signal peak above threshold found at index 3 with value 22.'\n>>> with patch('builtins.print') as mock_print:\n...     new_signal = [5, 7, 9, 22, 15, 19]\n...     (index, value) = threshold_peak(new_signal, threshold)\n...     mock_print.assert_called_once_with(expected_message)\n>>> if mock_print.call_args[0][0] == expected_message:\n...     score = 2\n...     drexel_jupyter_logger.variable_logger_csv('2, 2', question_id)\n... else:\n...     score = 0\n>>> response = {'question_id': question_id, 'score': score, 'max_score': 2, 'student_response': f'{mock_print.call_args[0][0]}'}\n>>> scorer.add_response(response)\n>>> scorer.submit()\nLogin successful\nData successfully uploaded to the server\nresponses successfully uploaded to database\n",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "Test for stress implemented correctly."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> from ENGR131_Util_2024 import submit_score\n>>> scorer = submit_score()\n>>> question_id = 'q2_3'\n>>> with patch('builtins.print') as mock_print:\n...     new_signal = [5, 7, 9, 22, 15, 19]\n...     pk = threshold_peak(new_signal, threshold)\n...     assert isinstance(pk, tuple), 'The function does not return a tuple.'\n...     assert pk == (3, 22), 'The function does not return the correct index and value.'\n>>> if isinstance(pk, tuple) and pk == (3, 22):\n...     score = 3\n...     drexel_jupyter_logger.variable_logger_csv('3, 3', question_id)\n... else:\n...     score = 0\n>>> response = {'question_id': question_id, 'score': score, 'max_score': 3, 'student_response': f'{pk}, {type(pk)}'}\n>>> scorer.add_response(response)\n>>> scorer.submit()\nLogin successful\nData successfully uploaded to the server\nresponses successfully uploaded to database\n",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "Function correctly returns a numerical value."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> from ENGR131_Util_2024 import submit_score\n>>> scorer = submit_score()\n>>> question_id = 'q2_4'\n>>> expected_message = 'No significant signal peak was detected above the threshold of 20.'\n>>> with patch('builtins.print') as mock_print:\n...     threshold = 20\n...     out = threshold_peak([1, 2, 3], threshold)\n...     mock_print.assert_called_once_with(expected_message)\n...     assert None == out, 'The function should return None for both index and value when no peak exceeds the threshold.'\n>>> if mock_print.call_args[0][0] == expected_message and None == out:\n...     score = 3\n...     drexel_jupyter_logger.variable_logger_csv('3, 3', question_id)\n... else:\n...     score = 0\n>>> response = {'question_id': question_id, 'score': score, 'max_score': 3, 'student_response': f'{mock_print.call_args[0][0]}, {out}'}\n>>> scorer.add_response(response)\n>>> scorer.submit()\nLogin successful\nData successfully uploaded to the server\nresponses successfully uploaded to database\n",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "default safety factor is implemented correctly."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> from ENGR131_Util_2024 import submit_score\n>>> scorer = submit_score()\n>>> question_id = 'q2_5'\n>>> with patch('builtins.print') as mock_print:\n...     assert peak == (6, 21), 'The peak index and value do not match the expected output.'\n>>> if peak == (6, 21):\n...     score = 4\n...     drexel_jupyter_logger.variable_logger_csv('4, 4', question_id)\n... else:\n...     score = 0\n>>> response = {'question_id': question_id, 'score': score, 'max_score': 3, 'student_response': f'{peak}'}\n>>> scorer.add_response(response)\n>>> scorer.submit()\nLogin successful\nData successfully uploaded to the server\nresponses successfully uploaded to database\n",
         "hidden": false,
         "locked": false,
         "points": 4,
         "success_message": "peak does not return the correct value."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
